{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c2d431",
   "metadata": {},
   "source": [
    "# LazyFox Analysis\n",
    "\n",
    "This notebook showcases an analysis of a LazyFox run on Eu-core dataset with a threadcount of 1. This is equivalent to the output of the examplatory run of the `LazyFox Workflow.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b88178",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "You can change the `run_directory` below if you want to run on the output created from the `LazyFox Workflow.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87cae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "run_directory = \"./example_data/run_eu_with_1\"\n",
    "\n",
    "if not os.path.exists(run_directory):\n",
    "    raise ValueError(f\"No such run directory '{run_directory}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83086ba8",
   "metadata": {},
   "source": [
    "As the input data provided by SNAP does not always contain the graph properties 'node count' and 'edge count' they are hard coded. Therefore you need to specify the dataset you used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5b553",
   "metadata": {},
   "source": [
    "The following class bundles many usefull methods to analyse the result of a LazyFox run. It is defined in `BechmarkRun.py`. If you are not interested in the inner workings of the analysis, you can skip that.\n",
    "\n",
    "However, if you want to run on a new dataset apart from Eu-core, DBLP or LiveJournal, you will have to add the node count and the edge count of the new dataset to the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BenchmarkRun import BenchmarkRun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbb6b7",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "To analyse a LazyFox run, we create a `BenchmarkRun` object. It just needs the dataset (to lookup the node count and edge count) and the run directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = BenchmarkRun(dataset, run_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb36b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "cluster_stats = run.cluster_stats()\n",
    "DataFrame([cluster_stats.values()], columns=cluster_stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_stats = run.performance_stats()\n",
    "DataFrame([performance_stats.values()], columns=performance_stats.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ae588c",
   "metadata": {},
   "source": [
    "## Comparative Analysis\n",
    "If you run LazyFox multiple times you can create multiple `BenchmarkRun` objects and then compare their results.\n",
    "\n",
    "We provided the output of multiple LazyFox runs on the Eu-core dataset to showcase a more advanced analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cd914",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_directory = \"./example_data\"\n",
    "\n",
    "runs_by_threadcount = {}\n",
    "\n",
    "threadcounts = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "for threadcount in threadcounts:\n",
    "    run_directory = os.path.join(example_data_directory, f\"run_eu_with_{threadcount}\")\n",
    "\n",
    "    runs_by_threadcount[threadcount] = BenchmarkRun(\"eu\", run_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6c4de",
   "metadata": {},
   "source": [
    "### Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Stats\n",
    "data_rows = []\n",
    "for threadcount in threadcounts:\n",
    "    run = runs_by_threadcount[threadcount]\n",
    "    cluster_stats = run.cluster_stats()\n",
    "\n",
    "    if threadcount == 1:\n",
    "        org = cluster_stats\n",
    "\n",
    "    def display_diff(value, org, threadcount):\n",
    "        new = round(value - org, 2)\n",
    "        if threadcount != 1 and new >= 0:\n",
    "            return \"+\" + str(new)\n",
    "        return str(new)\n",
    "\n",
    "    data_row = [threadcount] + [display_diff(value,org[key], threadcount) for key, value in cluster_stats.items()]\n",
    "    data_rows.append(data_row)\n",
    "\n",
    "cluster_stat_df = DataFrame(data_rows, columns=[\"threadcount\"] + list(cluster_stats.keys()))\n",
    "cluster_stat_df.style.set_caption(\"EU Dataset - Cluster Stat Changes over different threadcounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Performance Stats\n",
    "data_rows = []\n",
    "for threadcount in threadcounts:\n",
    "    run = runs_by_threadcount[threadcount]\n",
    "    performance_stats = run.performance_stats()\n",
    "\n",
    "    if threadcount == 1:\n",
    "        org = performance_stats\n",
    "\n",
    "    def display_diff(value, org, threadcount):\n",
    "        new = round(value - org, 2)\n",
    "        if threadcount != 1 and new >= 0:\n",
    "            return \"+\" + str(new)\n",
    "        return str(new)\n",
    "\n",
    "    data_row = [threadcount] + [display_diff(value,org[key], threadcount) for key, value in performance_stats.items()]\n",
    "    data_rows.append(data_row)\n",
    "\n",
    "performance_stat_df = DataFrame(data_rows, columns=[\"threadcount\"] + list(performance_stats.keys()))\n",
    "performance_stat_df.style.set_caption(\"EU Dataset - Performance Stat Changes over different threadcounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd678855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Performance Stats\n",
    "baselines_stats = runs_by_threadcount[1].performance_stats()\n",
    "\n",
    "data_rows = []\n",
    "for threadcount in threadcounts:\n",
    "    run = runs_by_threadcount[threadcount]\n",
    "    performance_stats = run.performance_stats()\n",
    "    # Make the stats relative to threadcount 1\n",
    "    for key in performance_stats:\n",
    "        performance_stats[key] = performance_stats[key] / baselines_stats[key]\n",
    "\n",
    "    if threadcount == 1:\n",
    "        org = performance_stats\n",
    "\n",
    "\n",
    "    data_row = [threadcount] + [value for key, value in performance_stats.items()]\n",
    "    data_rows.append(data_row)\n",
    "\n",
    "rel_performance_stat_df = DataFrame(data_rows, columns=[\"threadcount\"] + list(performance_stats.keys()))\n",
    "rel_performance_stat_df.style.set_caption(\"EU Dataset - Relative Performance Stat Changes over different threadcounts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb63a3a",
   "metadata": {},
   "source": [
    "### Plot Performance Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(20,5))\n",
    "fig.suptitle(\"EU Core - Relative Performance Compared to FOX\")\n",
    "rel_performance_stat_df\n",
    "\n",
    "for i, column in enumerate([\"ram peak\", \"total time\", \"avg time per iteration\"]):\n",
    "    axes[i].set_title(f\"{column}\")\n",
    "    axes[i].plot(rel_performance_stat_df[\"threadcount\"], rel_performance_stat_df[column], label=\"eu\")\n",
    "    axes[i].set_xticks(threadcounts)\n",
    "    axes[i].set_xlabel(\"Threadcount\")\n",
    "    axes[i].set_ylabel(\"Relative Change\")\n",
    "    axes[i].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d910296",
   "metadata": {},
   "source": [
    "We can see that the maximum RAM consumed sacles aprox. linearly with the threadcount. The runtime however gets reduced fairly exponentially, caused by the speedup in the individual iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4cbd6",
   "metadata": {},
   "source": [
    "### Plot WCC Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a800a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WCC Diff over iteration\n",
    "\n",
    "iterations = {}\n",
    "for threadcount in threadcounts:\n",
    "    r = runs_by_threadcount[threadcount]\n",
    "    iterations[threadcount] = [threadcount] + [i[\"wcc_diff\"] for i in r.iterations]\n",
    "\n",
    "df = DataFrame(list(iterations.values())).transpose()\n",
    "df.columns = list(map(int, df.iloc[0]))\n",
    "df = df.drop(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,7))\n",
    "fig.suptitle(\"EU Core - WCC Development\")\n",
    "# Plot wcc fidd over iterations\n",
    "df.plot(\n",
    "    xlabel=\"#iteration\",\n",
    "    ylabel=\"wcc change (log)\",\n",
    "    logy=True,\n",
    "    marker='o',\n",
    "    xticks=list(df.index),\n",
    "    title=\"\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Plot wcc diffs\n",
    "for wcc_diff in [0.01 * x for x in range(1, 5)]:\n",
    "    plt.axhline(y=wcc_diff, color='r', linestyle=':')\n",
    "    plt.text(df.index[-1] + 1.5, wcc_diff, str(wcc_diff), color=\"red\")\n",
    "plt.legend(title=\"Threadcount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5691c4b",
   "metadata": {},
   "source": [
    "We can see that the wcc changes are dependent on the threadcount. Note that this is due to the low node count in the used EU-Core dataset and is an exception. Refer to the report of this project for further details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
